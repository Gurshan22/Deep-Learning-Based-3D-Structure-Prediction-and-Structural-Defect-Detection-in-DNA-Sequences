# -*- coding: utf-8 -*-
"""Untitled39.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LfC94sSez9SK7NELG94t0LU4dfgwm0Ig
"""

# -*- coding: utf-8 -*-
"""Deep Learning DNA Structure Analysis Pipeline

A comprehensive deep learning system for DNA structure prediction and analysis.
Converts the original ML project to use neural networks while maintaining all outputs.
Includes interactive mode for single DNA sequence analysis.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, f1_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# Deep Learning imports
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, LSTM, Embedding, Conv1D, GlobalMaxPooling1D
from tensorflow.keras.optimizers import Adam, RMSprop
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.regularizers import l2
import tensorflow.keras.backend as K

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

import Bio
try:
    from Bio.PDB import PDBParser, PDBIO
    from Bio.SeqUtils import GC
    BIOPYTHON_AVAILABLE = True
except ImportError:
    print("BioPython not available. Some features will be limited.")
    BIOPYTHON_AVAILABLE = False

class DNADeepLearningAnalyzer:
    def __init__(self):
        self.data = None
        self.models = {}
        self.history = {}
        self.encoders = {}
        self.scaler = StandardScaler()
        self.sequence_scaler = MinMaxScaler()
        self.system_performance = {}
        self.sequence_length = 20  # Max sequence length for padding
        self.nucleotide_mapping = {'A': 0, 'T': 1, 'G': 2, 'C': 3, 'N': 4}
        self.demographic_models = {}
        self.demographic_history = {}


    def generate_synthetic_dataset(self):
        """Generate synthetic dataset based on specified demographics"""
        np.random.seed(42)

        # Generate demographic data
        n_samples = 536  # 236 women + 300 men

        # Gender distribution
        gender = ['Female'] * 236 + ['Male'] * 300

        # Race distribution (realistic proportions)
        races = ['Caucasian', 'African American', 'Asian', 'Hispanic', 'Native American', 'Mixed/Other']
        race_probs = [0.45, 0.25, 0.15, 0.08, 0.03, 0.04]
        race = np.random.choice(races, n_samples, p=race_probs)

        # Age distribution
        age = np.random.normal(45, 15, n_samples).astype(int)
        age = np.clip(age, 18, 85)

        # Health status: 100 cardiovascular, 436 healthy
        health_status = ['Healthy'] * 436 + ['Cardiovascular'] * 100
        np.random.shuffle(health_status)

        # Generate DNA sequences (variable lengths, but we'll pad to fixed length)
        def generate_dna_sequence(length=None):
            if length is None:
                length = np.random.randint(8, 16)  # Variable length sequences
            return ''.join(np.random.choice(['A', 'T', 'G', 'C'], length))

        dna_sequences = [generate_dna_sequence() for _ in range(n_samples)]

        # Generate structural features
        def calculate_features(seq):
            features = {
                'gc_content': (seq.count('G') + seq.count('C')) / len(seq),
                'purine_content': (seq.count('A') + seq.count('G')) / len(seq),
                'pyrimidine_content': (seq.count('C') + seq.count('T')) / len(seq),
                'length': len(seq),
                'a_count': seq.count('A'),
                't_count': seq.count('T'),
                'g_count': seq.count('G'),
                'c_count': seq.count('C'),
                'at_ratio': seq.count('A') / (seq.count('T') + 1e-10),
                'gc_ratio': seq.count('G') / (seq.count('C') + 1e-10),
                'cg_dinucleotides': seq.count('CG'),
                'ta_dinucleotides': seq.count('TA'),
                'at_dinucleotides': seq.count('AT'),
                'gc_dinucleotides': seq.count('GC'),
                'melting_temp': 2 * (seq.count('A') + seq.count('T')) + 4 * (seq.count('G') + seq.count('C')),
                'stability_score': (seq.count('G') + seq.count('C')) * 4 + (seq.count('A') + seq.count('T')) * 2,
                'twist_angle': 36.0 + np.random.normal(0, 2),
                'rise_per_bp': 3.4 + np.random.normal(0, 0.1),
                'groove_width': 12.0 + np.random.normal(0, 1),
                'backbone_distance': 20.0 + np.random.normal(0, 0.5)
            }
            return features

        # Calculate features for all sequences
        feature_data = [calculate_features(seq) for seq in dna_sequences]
        feature_df = pd.DataFrame(feature_data)

        # Create the main dataset
        self.data = pd.DataFrame({
            'ID': range(1, n_samples + 1),
            'Gender': gender,
            'Race': race,
            'Age': age,
            'Health_Status': health_status,
            'DNA_Sequence': dna_sequences,
        })

        # Add features
        self.data = pd.concat([self.data, feature_df], axis=1)

        # Generate target variables (same logic as original)
        structure_prob = (
            0.25 * (self.data['Health_Status'] == 'Cardiovascular').astype(int) +
            0.20 * (self.data['gc_content'] > 0.65).astype(int) +
            0.15 * (self.data['melting_temp'] > 45).astype(int) +
            0.10 * (self.data['Age'] > 60).astype(int) +
            0.10 * (self.data['Gender'] == 'Male').astype(int) +
            0.10 * (self.data['cg_dinucleotides'] > 2).astype(int) +
            0.10 * np.random.random(n_samples)
        )
        self.data['Structure_3D'] = np.where(structure_prob > 0.45, 'Distorted', 'Normal')

        defect_prob = (
            0.30 * (self.data['Health_Status'] == 'Cardiovascular').astype(int) +
            0.20 * (self.data['gc_content'] < 0.35).astype(int) +
            0.15 * (self.data['stability_score'] < 30).astype(int) +
            0.10 * (self.data['Age'] > 55).astype(int) +
            0.10 * (self.data['cg_dinucleotides'] == 0).astype(int) +
            0.05 * (self.data['Race'] == 'African American').astype(int) +
            0.10 * np.random.random(n_samples)
        )
        self.data['Structural_Defect'] = np.where(defect_prob > 0.5, 'Present', 'Absent')

        print(f"Dataset created with {len(self.data)} samples")
        print(f"Demographics: {len(self.data[self.data['Gender']=='Female'])} Women, {len(self.data[self.data['Gender']=='Male'])} Men")
        print(f"Health Status: {len(self.data[self.data['Health_Status']=='Healthy'])} Healthy, {len(self.data[self.data['Health_Status']=='Cardiovascular'])} Cardiovascular")
        return self.data

    def create_comprehensive_demographic_report(self):
        """Generate comprehensive demographic analysis report - Same as original"""
        print("\n" + "="*80)
        print("COMPREHENSIVE DEMOGRAPHIC ANALYSIS REPORT")
        print("="*80)

        # Basic Demographics
        print("\n1. BASIC DEMOGRAPHICS")
        print("-" * 40)

        # Gender Distribution
        gender_dist = self.data['Gender'].value_counts()
        gender_pct = self.data['Gender'].value_counts(normalize=True) * 100
        print(f"Gender Distribution:")
        for gender in gender_dist.index:
            print(f"  {gender}: {gender_dist[gender]} ({gender_pct[gender]:.1f}%)")

        # Race Distribution
        race_dist = self.data['Race'].value_counts()
        race_pct = self.data['Race'].value_counts(normalize=True) * 100
        print(f"\nRace Distribution:")
        for race in race_dist.index:
            print(f"  {race}: {race_dist[race]} ({race_pct[race]:.1f}%)")

        # Age Statistics
        print(f"\nAge Statistics:")
        print(f"  Mean Age: {self.data['Age'].mean():.1f} years")
        print(f"  Median Age: {self.data['Age'].median():.1f} years")
        print(f"  Age Range: {self.data['Age'].min()} - {self.data['Age'].max()} years")
        print(f"  Standard Deviation: {self.data['Age'].std():.1f} years")

        # Health Status
        health_dist = self.data['Health_Status'].value_counts()
        health_pct = self.data['Health_Status'].value_counts(normalize=True) * 100
        print(f"\nHealth Status Distribution:")
        for status in health_dist.index:
            print(f"  {status}: {health_dist[status]} ({health_pct[status]:.1f}%)")

        # Cross-tabulations
        print("\n2. DEMOGRAPHIC CROSS-ANALYSIS")
        print("-" * 40)

        # Gender vs Health Status
        print("\nGender vs Health Status:")
        gender_health = pd.crosstab(self.data['Gender'], self.data['Health_Status'], margins=True)
        print(gender_health)

        # Race vs Health Status
        print("\nRace vs Health Status:")
        race_health = pd.crosstab(self.data['Race'], self.data['Health_Status'], margins=True)
        print(race_health)

        # Age groups vs Health Status
        self.data['Age_Group'] = pd.cut(self.data['Age'],
                                       bins=[0, 30, 45, 60, 100],
                                       labels=['18-30', '31-45', '46-60', '60+'])
        print("\nAge Group vs Health Status:")
        age_health = pd.crosstab(self.data['Age_Group'], self.data['Health_Status'], margins=True)
        print(age_health)

        # Structure and Defect Analysis by Demographics
        print("\n3. STRUCTURAL ANALYSIS BY DEMOGRAPHICS")
        print("-" * 40)

        # 3D Structure by Gender
        print("\n3D Structure Prediction by Gender:")
        struct_gender = pd.crosstab(self.data['Gender'], self.data['Structure_3D'], margins=True)
        print(struct_gender)

        # Structural Defects by Race
        print("\nStructural Defects by Race:")
        defect_race = pd.crosstab(self.data['Race'], self.data['Structural_Defect'], margins=True)
        print(defect_race)

        # Advanced Statistics
        print("\n4. ADVANCED STATISTICAL ANALYSIS")
        print("-" * 40)

        # GC Content by Demographics
        print("\nGC Content Statistics by Demographics:")
        gc_stats = self.data.groupby(['Gender', 'Health_Status'])['gc_content'].agg(['mean', 'std', 'count'])
        print(gc_stats)

        print("\nMelting Temperature by Race:")
        temp_stats = self.data.groupby('Race')['melting_temp'].agg(['mean', 'std', 'min', 'max'])
        print(temp_stats)

        # Risk Analysis
        print("\n5. RISK FACTOR ANALYSIS")
        print("-" * 40)

        # Calculate risk ratios
        total_cardio = len(self.data[self.data['Health_Status'] == 'Cardiovascular'])
        total_samples = len(self.data)
        baseline_risk = total_cardio / total_samples

        print(f"Baseline Cardiovascular Risk: {baseline_risk:.3f} ({baseline_risk*100:.1f}%)")

        # Risk by gender
        for gender in self.data['Gender'].unique():
            gender_data = self.data[self.data['Gender'] == gender]
            gender_cardio = len(gender_data[gender_data['Health_Status'] == 'Cardiovascular'])
            gender_risk = gender_cardio / len(gender_data)
            risk_ratio = gender_risk / baseline_risk
            print(f"{gender} Risk: {gender_risk:.3f} ({gender_risk*100:.1f}%) - Risk Ratio: {risk_ratio:.2f}")

        # Risk by age group
        for age_group in self.data['Age_Group'].unique():
            if pd.isna(age_group):
                continue
            age_data = self.data[self.data['Age_Group'] == age_group]
            age_cardio = len(age_data[age_data['Health_Status'] == 'Cardiovascular'])
            age_risk = age_cardio / len(age_data)
            risk_ratio = age_risk / baseline_risk
            print(f"Age {age_group} Risk: {age_risk:.3f} ({age_risk*100:.1f}%) - Risk Ratio: {risk_ratio:.2f}")

        # Create comprehensive visualizations
        self.create_demographic_visualizations()

        return {
            'gender_dist': gender_dist,
            'race_dist': race_dist,
            'health_dist': health_dist,
            'age_stats': self.data['Age'].describe(),
            'cross_tabs': {
                'gender_health': gender_health,
                'race_health': race_health,
                'age_health': age_health
            }
        }

    def create_demographic_visualizations(self):
        """Create comprehensive demographic visualizations - Same as original"""
        fig, axes = plt.subplots(3, 3, figsize=(20, 18))

        # Gender distribution
        self.data['Gender'].value_counts().plot(kind='bar', ax=axes[0,0], color=['pink', 'lightblue'])
        axes[0,0].set_title('Gender Distribution', fontsize=14, fontweight='bold')
        axes[0,0].set_ylabel('Count')
        axes[0,0].tick_params(axis='x', rotation=45)

        # Race distribution
        race_counts = self.data['Race'].value_counts()
        axes[0,1].pie(race_counts.values, labels=race_counts.index, autopct='%1.1f%%', startangle=90)
        axes[0,1].set_title('Race Distribution', fontsize=14, fontweight='bold')

        # Age distribution
        axes[0,2].hist(self.data['Age'], bins=20, alpha=0.7, color='green', edgecolor='black')
        axes[0,2].set_title('Age Distribution', fontsize=14, fontweight='bold')
        axes[0,2].set_xlabel('Age (years)')
        axes[0,2].set_ylabel('Frequency')

        # Health status
        health_counts = self.data['Health_Status'].value_counts()
        colors = ['lightgreen' if x == 'Healthy' else 'salmon' for x in health_counts.index]
        health_counts.plot(kind='bar', ax=axes[1,0], color=colors)
        axes[1,0].set_title('Health Status Distribution', fontsize=14, fontweight='bold')
        axes[1,0].tick_params(axis='x', rotation=45)

        # GC Content by Health Status
        healthy_gc = self.data[self.data['Health_Status'] == 'Healthy']['gc_content']
        cardio_gc = self.data[self.data['Health_Status'] == 'Cardiovascular']['gc_content']
        axes[1,1].hist([healthy_gc, cardio_gc], bins=20, alpha=0.7,
                      label=['Healthy', 'Cardiovascular'], color=['green', 'red'])
        axes[1,1].set_title('GC Content by Health Status', fontsize=14, fontweight='bold')
        axes[1,1].set_xlabel('GC Content')
        axes[1,1].legend()

        # Structure prediction distribution
        struct_counts = self.data['Structure_3D'].value_counts()
        colors = ['lightblue' if x == 'Normal' else 'orange' for x in struct_counts.index]
        struct_counts.plot(kind='bar', ax=axes[1,2], color=colors)
        axes[1,2].set_title('3D Structure Prediction', fontsize=14, fontweight='bold')
        axes[1,2].tick_params(axis='x', rotation=45)

        # Defect prediction distribution
        defect_counts = self.data['Structural_Defect'].value_counts()
        colors = ['lightcoral' if x == 'Present' else 'lightsteelblue' for x in defect_counts.index]
        defect_counts.plot(kind='bar', ax=axes[2,0], color=colors)
        axes[2,0].set_title('Structural Defect Prediction', fontsize=14, fontweight='bold')
        axes[2,0].tick_params(axis='x', rotation=45)

        # Melting temperature distribution
        axes[2,1].hist(self.data['melting_temp'], bins=25, alpha=0.7, color='purple', edgecolor='black')
        axes[2,1].set_title('Melting Temperature Distribution', fontsize=14, fontweight='bold')
        axes[2,1].set_xlabel('Melting Temperature (°C)')
        axes[2,1].set_ylabel('Frequency')

        # Age vs GC Content scatter
        scatter = axes[2,2].scatter(self.data['Age'], self.data['gc_content'],
                                   c=self.data['Health_Status'].map({'Healthy': 0, 'Cardiovascular': 1}),
                                   cmap='RdYlBu', alpha=0.6)
        axes[2,2].set_title('Age vs GC Content', fontsize=14, fontweight='bold')
        axes[2,2].set_xlabel('Age (years)')
        axes[2,2].set_ylabel('GC Content')
        plt.colorbar(scatter, ax=axes[2,2], label='Health Status')

        plt.tight_layout()
        plt.show()

        # Additional correlation heatmap
        plt.figure(figsize=(14, 10))
        numeric_cols = self.data.select_dtypes(include=[np.number]).columns
        correlation_matrix = self.data[numeric_cols].corr()

        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
                   square=True, linewidths=0.5, cbar_kws={"shrink": .8})
        plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.show()


    def create_performance_visualizations(self, results):
        """Create visualizations for model performance metrics"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # Plot ROC curves
        axes[0,0].set_title('ROC Curves for Structure Prediction Models', fontsize=14, fontweight='bold')
        axes[0,0].plot([0, 1], [0, 1], 'k--', label='Random')
        for model_name in ['dense_structure', 'seq_structure', 'hybrid_structure']:
            if model_name in results and 'fpr' in results[model_name] and 'tpr' in results[model_name]:
                axes[0,0].plot(results[model_name]['fpr'], results[model_name]['tpr'],
                               label=f'{model_name.replace("_", " ").title()} (AUC = {results[model_name]["roc_auc"]:.4f})')
        axes[0,0].set_xlabel('False Positive Rate')
        axes[0,0].set_ylabel('True Positive Rate')
        axes[0,0].legend()
        axes[0,0].grid(True, alpha=0.3)

        axes[0,1].set_title('ROC Curves for Defect Prediction Models', fontsize=14, fontweight='bold')
        axes[0,1].plot([0, 1], [0, 1], 'k--', label='Random')
        for model_name in ['dense_defect', 'seq_defect', 'hybrid_defect']:
            if model_name in results and 'fpr' in results[model_name] and 'tpr' in results[model_name]:
                axes[0,1].plot(results[model_name]['fpr'], results[model_name]['tpr'],
                               label=f'{model_name.replace("_", " ").title()} (AUC = {results[model_name]["roc_auc"]:.4f})')
        axes[0,1].set_xlabel('False Positive Rate')
        axes[0,1].set_ylabel('True Positive Rate')
        axes[0,1].legend()
        axes[0,1].grid(True, alpha=0.3)

        # Plot Accuracy, F1, and AUC
        metrics_df = pd.DataFrame({
            'Model': [name.replace('_', ' ').title() for name in results.keys()],
            'Task': ['Structure'] * 3 + ['Defect'] * 3,
            'Accuracy': [results[name]['accuracy'] for name in results.keys()],
            'F1 Score': [results[name]['f1'] for name in results.keys()],
            'ROC AUC': [results[name]['roc_auc'] for name in results.keys()]
        })

        metrics_df_melted = metrics_df.melt(id_vars=['Model', 'Task'], var_name='Metric', value_name='Score')

        sns.barplot(x='Model', y='Score', hue='Task', data=metrics_df_melted[metrics_df_melted['Metric'] == 'Accuracy'], ax=axes[1,0], palette='viridis')
        axes[1,0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')
        axes[1,0].set_ylabel('Accuracy')
        axes[1,0].tick_params(axis='x', rotation=45)
        axes[1,0].set_ylim(0, 1.0)
        axes[1,0].grid(True, alpha=0.3)

        sns.barplot(x='Model', y='Score', hue='Task', data=metrics_df_melted[metrics_df_melted['Metric'].isin(['F1 Score', 'ROC AUC'])], ax=axes[1,1], palette='magma')
        axes[1,1].set_title('Model F1 Score and ROC AUC Comparison', fontsize=14, fontweight='bold')
        axes[1,1].set_ylabel('Score')
        axes[1,1].tick_params(axis='x', rotation=45)
        axes[1,1].set_ylim(0, 1.0)
        axes[1,1].grid(True, alpha=0.3)


        plt.tight_layout()
        plt.show()


    def encode_sequence(self, sequence):
        """Convert DNA sequence to numerical representation for neural networks"""
        # Pad sequence to fixed length
        padded_seq = sequence.ljust(self.sequence_length, 'N')[:self.sequence_length]

        # Convert to numerical representation
        encoded = [self.nucleotide_mapping.get(nucleotide, 4) for nucleotide in padded_seq]

        return np.array(encoded)

    def preprocess_data(self):
        """Preprocess the data for deep learning"""
        # Encode categorical variables
        categorical_cols = ['Gender', 'Race', 'Health_Status']

        for col in categorical_cols:
            le = LabelEncoder()
            self.data[f'{col}_encoded'] = le.fit_transform(self.data[col])
            self.encoders[col] = le

        # Encode DNA sequences
        self.data['DNA_Encoded'] = self.data['DNA_Sequence'].apply(self.encode_sequence)

        # Prepare numerical features for ML
        feature_cols = [col for col in self.data.columns if col not in
                       ['ID', 'DNA_Sequence', 'DNA_Encoded', 'Structure_3D', 'Structural_Defect',
                        'Gender', 'Race', 'Health_Status', 'Age_Group']] # Exclude Age_Group

        self.X_numerical = self.data[feature_cols]
        self.X_numerical_scaled = self.scaler.fit_transform(self.X_numerical)

        # Prepare sequence data for LSTM/CNN
        self.X_sequences = np.array(list(self.data['DNA_Encoded']))

        # Prepare targets
        le_structure = LabelEncoder()
        le_defect = LabelEncoder()

        self.y_structure = le_structure.fit_transform(self.data['Structure_3D'])
        self.y_defect = le_defect.fit_transform(self.data['Structural_Defect'])

        self.encoders['Structure_3D'] = le_structure
        self.encoders['Structural_Defect'] = le_defect

        print("Data preprocessing completed")
        print(f"Numerical feature matrix shape: {self.X_numerical_scaled.shape}")
        print(f"Sequence matrix shape: {self.X_sequences.shape}")
        print(f"Features used: {list(self.X_numerical.columns)}")
        return self.X_numerical_scaled, self.X_sequences, self.y_structure, self.y_defect

    def create_dense_neural_network(self, input_dim, output_classes, model_name):
        """Create a deep dense neural network"""
        model = Sequential([
            Input(shape=(input_dim,)),
            Dense(256, activation='relu', kernel_regularizer=l2(0.001)),
            BatchNormalization(),
            Dropout(0.3),

            Dense(128, activation='relu', kernel_regularizer=l2(0.001)),
            BatchNormalization(),
            Dropout(0.3),

            Dense(64, activation='relu', kernel_regularizer=l2(0.001)),
            BatchNormalization(),
            Dropout(0.2),

            Dense(32, activation='relu'),
            Dropout(0.2),

            Dense(1 if output_classes == 2 else output_classes, activation='sigmoid' if output_classes == 2 else 'softmax')
        ])

        # Compile model
        optimizer = Adam(learning_rate=0.001)
        loss_function = 'binary_crossentropy' if output_classes == 2 else 'sparse_categorical_crossentropy'
        model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])

        model.summary()
        return model

    def create_sequence_neural_network(self, sequence_length, vocab_size, output_classes, model_name):
        """Create a neural network for sequence data (LSTM + CNN)"""
        # Input layer
        sequence_input = Input(shape=(sequence_length,))

        # Embedding layer
        embedded = Embedding(vocab_size, 64, input_length=sequence_length)(sequence_input)

        # CNN branch
        conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(embedded)
        conv2 = Conv1D(filters=32, kernel_size=5, activation='relu')(conv1)
        cnn_output = GlobalMaxPooling1D()(conv2)

        # Dense layers
        dense1 = Dense(128, activation='relu')(cnn_output)
        dense1 = BatchNormalization()(dense1)
        dense1 = Dropout(0.3)(dense1)

        dense2 = Dense(64, activation='relu')(dense1)
        dense2 = Dropout(0.2)(dense2)

        # Output layer
        if output_classes == 2:
            output = Dense(1, activation='sigmoid')(dense2)
            loss = 'binary_crossentropy'
        else:
            output = Dense(output_classes, activation='softmax')(dense2)
            loss = 'sparse_categorical_crossentropy'


        model = Model(inputs=sequence_input, outputs=output)

        # Compile model
        optimizer = Adam(learning_rate=0.001)
        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])

        model.summary()
        return model

    def create_hybrid_neural_network(self, numerical_dim, sequence_length, vocab_size, output_classes, model_name):
        """Create a hybrid neural network combining numerical and sequence data"""
        # Numerical input branch
        numerical_input = Input(shape=(numerical_dim,), name='numerical_input')
        numerical_dense1 = Dense(128, activation='relu')(numerical_input)
        numerical_dense1 = BatchNormalization()(numerical_dense1)
        numerical_dense1 = Dropout(0.3)(numerical_dense1)

        numerical_dense2 = Dense(64, activation='relu')(numerical_dense1)
        numerical_branch = Dropout(0.2)(numerical_dense2)

        # Sequence input branch
        sequence_input = Input(shape=(sequence_length,), name='sequence_input')
        embedded = Embedding(vocab_size, 32, input_length=sequence_length)(sequence_input)

        conv1 = Conv1D(filters=32, kernel_size=3, activation='relu')(embedded)
        conv2 = Conv1D(filters=16, kernel_size=5, activation='relu')(conv1)
        sequence_branch = GlobalMaxPooling1D()(conv2)

        # Combine branches
        combined = tf.keras.layers.concatenate([numerical_branch, sequence_branch])

        # Final layers
        dense1 = Dense(64, activation='relu')(combined)
        dense1 = BatchNormalization()(dense1)
        dense1 = Dropout(0.3)(dense1)

        dense2 = Dense(32, activation='relu')(dense1)
        dense2 = Dropout(0.2)(dense2)

        # Output layer
        if output_classes == 2:
            output = Dense(1, activation='sigmoid')(dense2)
            loss = 'binary_crossentropy'
        else:
            output = Dense(output_classes, activation='softmax')(dense2)
            loss = 'sparse_categorical_crossentropy'

        model = Model(inputs=[numerical_input, sequence_input], outputs=output)

        # Compile model
        optimizer = Adam(learning_rate=0.001)
        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])

        model.summary()
        return model


    def train_deep_learning_models(self):
        """Train multiple deep learning models"""
        # Split data with stratification
        X_num_train, X_num_test, X_seq_train, X_seq_test, y_struct_train, y_struct_test = train_test_split(
            self.X_numerical_scaled, self.X_sequences, self.y_structure,
            test_size=0.2, random_state=42, stratify=self.y_structure)

        _, _, _, _, y_defect_train, y_defect_test = train_test_split(
            self.X_numerical_scaled, self.X_sequences, self.y_defect,
            test_size=0.2, random_state=42, stratify=self.y_defect)

        # Reshape target variables for binary crossentropy (ensure shape is (None, 1))
        y_struct_train = y_struct_train.reshape(-1, 1)
        y_struct_test = y_struct_test.reshape(-1, 1)
        y_defect_train = y_defect_train.reshape(-1, 1)
        y_defect_test = y_defect_test.reshape(-1, 1)

        print(f"y_struct_train shape before training: {y_struct_train.shape}")
        print(f"y_struct_test shape before training: {y_struct_test.shape}")
        print(f"y_defect_train shape before training: {y_defect_train.shape}")
        print(f"y_defect_test shape before training: {y_defect_test.shape}")


        # Define callbacks
        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)

        # Train models for structure prediction
        print("Training Deep Learning models...")
        print("\n1. Training Dense Neural Network for Structure Prediction...")

        # Dense model for structure prediction
        dense_structure_model = self.create_dense_neural_network(
            self.X_numerical_scaled.shape[1], 2, "dense_structure")

        history_dense_struct = dense_structure_model.fit(
            X_num_train, y_struct_train,
            validation_data=(X_num_test, y_struct_test),
            epochs=100, batch_size=32,
            callbacks=[early_stopping, reduce_lr],
            verbose=1
        )

        self.models['dense_structure'] = dense_structure_model
        self.history['dense_structure'] = history_dense_struct

        print("\n2. Training Sequence Neural Network for Structure Prediction...")

        # Sequence model for structure prediction
        seq_structure_model = self.create_sequence_neural_network(
            self.sequence_length, len(self.nucleotide_mapping), 2, "seq_structure")

        history_seq_struct = seq_structure_model.fit(
            X_seq_train, y_struct_train,
            validation_data=(X_seq_test, y_struct_test),
            epochs=100, batch_size=32,
            callbacks=[early_stopping, reduce_lr],
            verbose=1
        )

        self.models['seq_structure'] = seq_structure_model
        self.history['seq_structure'] = history_seq_struct

        print("\n3. Training Hybrid Neural Network for Structure Prediction...")

        # Hybrid model for structure prediction
        hybrid_structure_model = self.create_hybrid_neural_network(
            self.X_numerical_scaled.shape[1], self.sequence_length,
            len(self.nucleotide_mapping), 2, "hybrid_structure")

        history_hybrid_struct = hybrid_structure_model.fit(
            [X_num_train, X_seq_train], y_struct_train,
            validation_data=([X_num_test, X_seq_test], y_struct_test),
            epochs=100, batch_size=32,
            callbacks=[early_stopping, reduce_lr],
            verbose=1
        )

        self.models['hybrid_structure'] = hybrid_structure_model
        self.history['hybrid_structure'] = history_hybrid_struct

        print("\n4. Training Dense Neural Network for Defect Prediction...")

        # Dense model for defect prediction
        dense_defect_model = self.create_dense_neural_network(
            self.X_numerical_scaled.shape[1], 2, "dense_defect")

        history_dense_defect = dense_defect_model.fit(
            X_num_train, y_defect_train,
            validation_data=(X_num_test, y_defect_test),
            epochs=100, batch_size=32,
            callbacks=[early_stopping, reduce_lr],
            verbose=1
        )

        self.models['dense_defect'] = dense_defect_model
        self.history['dense_defect'] = history_dense_defect

        print("\n5. Training Sequence Neural Network for Defect Prediction...")

        # Sequence model for defect prediction
        seq_defect_model = self.create_sequence_neural_network(
            self.sequence_length, len(self.nucleotide_mapping), 2, "seq_defect")

        history_seq_defect = seq_defect_model.fit(
            X_seq_train, y_defect_train,
            validation_data=(X_seq_test, y_defect_test),
            epochs=100, batch_size=32,
            callbacks=[early_stopping, reduce_lr],
            verbose=1
        )

        self.models['seq_defect'] = seq_defect_model
        self.history['seq_defect'] = history_seq_defect

        print("\n6. Training Hybrid Neural Network for Defect Prediction...")

        # Hybrid model for defect prediction
        hybrid_defect_model = self.create_hybrid_neural_network(
            self.X_numerical_scaled.shape[1], self.sequence_length,
            len(self.nucleotide_mapping), 2, "hybrid_defect")

        history_hybrid_defect = hybrid_defect_model.fit(
            [X_num_train, X_seq_train], y_defect_train,
            validation_data=([X_num_test, X_seq_test], y_defect_test),
            epochs=100, batch_size=32,
            callbacks=[early_stopping, reduce_lr],
            verbose=1
        )

        self.models['hybrid_defect'] = hybrid_defect_model
        self.history['hybrid_defect'] = history_hybrid_defect

        # Store test data for evaluation
        self.test_data = {
            'X_num_train': X_num_train,
            'X_num_test': X_num_test,
            'X_seq_train': X_seq_train,
            'X_seq_test': X_seq_test,
            'y_structure_train': y_struct_train,
            'y_structure_test': y_struct_test,
            'y_defect_train': y_defect_train,
            'y_defect_test': y_defect_test
        }

        print("\nAll Deep Learning models trained successfully!")

        # Create training history visualization
        self.plot_training_history()

    def plot_training_history(self):
        """Plot training history for all models"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))

        models_to_plot = ['dense_structure', 'seq_structure', 'hybrid_structure',
                         'dense_defect', 'seq_defect', 'hybrid_defect']

        for i, model_name in enumerate(models_to_plot):
            if model_name in self.history:
                row = i // 3
                col = i % 3

                history = self.history[model_name]

                # Plot training & validation accuracy
                axes[row, col].plot(history.history['accuracy'], label='Training Accuracy', color='blue')
                axes[row, col].plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')
                axes[row, col].set_title(f'{model_name.replace("_", " ").title()} - Training History',
                                       fontweight='bold')
                axes[row, col].set_xlabel('Epochs')
                axes[row, col].set_ylabel('Accuracy')
                axes[row, col].legend()
                axes[row, col].grid(True, alpha=0.3)

                # Add loss as secondary axis
                ax2 = axes[row, col].twinx()
                ax2.plot(history.history['loss'], label='Training Loss', color='blue', alpha=0.3, linestyle='--')
                ax2.plot(history.history['val_loss'], label='Validation Loss', color='red', alpha=0.3, linestyle='--')
                ax2.set_ylabel('Loss')

        plt.tight_layout()
        plt.show()

    def calculate_comprehensive_accuracy(self):
        """Calculate comprehensive system accuracy metrics using deep learning models"""
        X_num_test = self.test_data['X_num_test']
        X_seq_test = self.test_data['X_seq_test']
        y_structure_test = self.test_data['y_structure_test']
        y_defect_test = self.test_data['y_defect_test']

        print("\n" + "="*80)
        print("COMPREHENSIVE DEEP LEARNING SYSTEM ACCURACY ANALYSIS")
        print("="*80)

        results = {}
        overall_metrics = {
            'structure_models': {},
            'defect_models': {},
            'system_overall': {}
        }

        # Evaluate structure prediction models
        print("\n1. 3D STRUCTURE PREDICTION ACCURACY (DEEP LEARNING)")
        print("-" * 60)

        structure_models = ['dense_structure', 'seq_structure', 'hybrid_structure']

        for model_name in structure_models:
            model = self.models[model_name]

            # Make predictions based on model type
            if model_name == 'dense_structure':
                y_pred_proba = model.predict(X_num_test)
            elif model_name == 'seq_structure':
                y_pred_proba = model.predict(X_seq_test)
            else:  # hybrid_structure
                y_pred_proba = model.predict([X_num_test, X_seq_test])

            # Convert probabilities to predictions
            if y_pred_proba.shape[-1] == 1: # Sigmoid output
                 y_pred_proba_binary = y_pred_proba.flatten()
                 y_pred = (y_pred_proba_binary > 0.5).astype(int)
            else: # Softmax output
                 y_pred = np.argmax(y_pred_proba, axis=1)
                 y_pred_proba_binary = y_pred_proba[:, 1] # Assuming the positive class is index 1


            # Calculate comprehensive metrics
            accuracy = accuracy_score(y_structure_test, y_pred)
            f1 = f1_score(y_structure_test, y_pred)
            fpr, tpr, _ = roc_curve(y_structure_test.flatten(), y_pred_proba_binary)
            roc_auc = auc(fpr, tpr)

            # Confusion matrix
            cm = confusion_matrix(y_structure_test.flatten(), y_pred)
            tn, fp, fn, tp = cm.ravel()

            # Additional metrics
            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            npv = tn / (tn + fn) if (tn + fn) > 0 else 0

            results[model_name] = {
                'accuracy': accuracy,
                'f1': f1,
                'roc_auc': roc_auc,
                'sensitivity': sensitivity,
                'specificity': specificity,
                'precision': precision,
                'npv': npv,
                'confusion_matrix': cm,
                'fpr': fpr,
                'tpr': tpr
            }

            overall_metrics['structure_models'][model_name] = {
                'accuracy': accuracy,
                'f1': f1,
                'roc_auc': roc_auc
            }

            print(f"\n{model_name.upper().replace('_', ' ')}:")
            print(f"  Accuracy:    {accuracy:.4f} ({accuracy*100:.2f}%)")
            print(f"  F1 Score:    {f1:.4f} ({f1*100:.2f}%)")
            print(f"  ROC AUC:     {roc_auc:.4f}")
            print(f"  Sensitivity: {sensitivity:.4f}")
            print(f"  Specificity: {specificity:.4f}")
            print(f"  Precision:   {precision:.4f}")
            print(f"  NPV:         {npv:.4f}")
            print("  Confusion Matrix:")
            print(cm)


        # Evaluate defect prediction models
        print("\n2. STRUCTURAL DEFECT PREDICTION ACCURACY (DEEP LEARNING)")
        print("-" * 60)

        defect_models = ['dense_defect', 'seq_defect', 'hybrid_defect']

        for model_name in defect_models:
            model = self.models[model_name]

            # Make predictions based on model type
            if model_name == 'dense_defect':
                y_pred_proba = model.predict(X_num_test)
            elif model_name == 'seq_defect':
                y_pred_proba = model.predict(X_seq_test)
            else:  # hybrid_defect
                y_pred_proba = model.predict([X_num_test, X_seq_test])

            # Convert probabilities to predictions
            if y_pred_proba.shape[-1] == 1: # Sigmoid output
                 y_pred_proba_binary = y_pred_proba.flatten()
                 y_pred = (y_pred_proba_binary > 0.5).astype(int)
            else: # Softmax output
                 y_pred = np.argmax(y_pred_proba, axis=1)
                 y_pred_proba_binary = y_pred_proba[:, 1] # Assuming the positive class is index 1

            # Calculate comprehensive metrics
            accuracy = accuracy_score(y_defect_test, y_pred)
            f1 = f1_score(y_defect_test, y_pred)
            fpr, tpr, _ = roc_curve(y_defect_test.flatten(), y_pred_proba_binary)
            roc_auc = auc(fpr, tpr)

            # Confusion matrix
            cm = confusion_matrix(y_defect_test.flatten(), y_pred)
            tn, fp, fn, tp = cm.ravel()

            # Additional metrics
            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            npv = tn / (tn + fn) if (tn + fn) > 0 else 0

            results[model_name] = {
                'accuracy': accuracy,
                'f1': f1,
                'roc_auc': roc_auc,
                'sensitivity': sensitivity,
                'specificity': specificity,
                'precision': precision,
                'npv': npv,
                'confusion_matrix': cm,
                'fpr': fpr,
                'tpr': tpr
            }

            overall_metrics['defect_models'][model_name] = {
                'accuracy': accuracy,
                'f1': f1,
                'roc_auc': roc_auc
            }

            print(f"\n{model_name.upper().replace('_', ' ')}:")
            print(f"  Accuracy:    {accuracy:.4f} ({accuracy*100:.2f}%)")
            print(f"  F1 Score:    {f1:.4f} ({f1*100:.2f}%)")
            print(f"  ROC AUC:     {roc_auc:.4f}")
            print(f"  Sensitivity: {sensitivity:.4f}")
            print(f"  Specificity: {specificity:.4f}")
            print(f"  Precision:   {precision:.4f}")
            print(f"  NPV:         {npv:.4f}")
            print("  Confusion Matrix:")
            print(cm)

        # System Overall Performance (using Hybrid Models as representative)
        print("\n3. SYSTEM OVERALL PERFORMANCE (USING HYBRID MODELS)")
        print("-" * 60)

        # Structure Prediction (Hybrid)
        structure_hybrid_results = results.get('hybrid_structure', {})
        print(f"\nHybrid Structure Prediction:")
        print(f"  Accuracy: {structure_hybrid_results.get('accuracy', 0):.4f}")
        print(f"  F1 Score: {structure_hybrid_results.get('f1', 0):.4f}")
        print(f"  ROC AUC:  {structure_hybrid_results.get('roc_auc', 0):.4f}")


        # Defect Prediction (Hybrid)
        defect_hybrid_results = results.get('hybrid_defect', {})
        print(f"\nHybrid Structural Defect Prediction:")
        print(f"  Accuracy: {defect_hybrid_results.get('accuracy', 0):.4f}")
        print(f"  F1 Score: {defect_hybrid_results.get('f1', 0):.4f}")
        print(f"  ROC AUC:  {defect_hybrid_results.get('roc_auc', 0):.4f}")


        # Average performance across tasks (using hybrid models)
        avg_accuracy = (structure_hybrid_results.get('accuracy', 0) + defect_hybrid_results.get('accuracy', 0)) / 2
        avg_f1 = (structure_hybrid_results.get('f1', 0) + defect_hybrid_results.get('f1', 0)) / 2
        avg_roc_auc = (structure_hybrid_results.get('roc_auc', 0) + defect_hybrid_results.get('roc_auc', 0)) / 2

        overall_metrics['system_overall'] = {
            'avg_accuracy': avg_accuracy,
            'avg_f1': avg_f1,
            'avg_roc_auc': avg_roc_auc
        }

        print("\nOverall System Performance (Average Hybrid Models):")
        print(f"  Average Accuracy: {avg_accuracy:.4f}")
        print(f"  Average F1 Score: {avg_f1:.4f}")
        print(f"  Average ROC AUC:  {avg_roc_auc:.4f}")

        self.system_performance = overall_metrics

        # Create performance visualizations
        self.create_performance_visualizations(results)

        return results, overall_metrics

    def comprehensive_analysis_report(self):
        """Generate a comprehensive analysis report combining demographic and accuracy findings."""
        if self.data is None:
            print("Please generate the synthetic dataset first.")
            return

        # Generate Demographic Report and Visualizations
        demographic_results = self.create_comprehensive_demographic_report()

        # Train Models and Calculate Accuracy Metrics
        # Ensure models are trained before calculating accuracy
        if not self.models:
             print("\nModels not trained yet. Training models...")
             self.train_deep_learning_models()

        accuracy_results, overall_performance = self.calculate_comprehensive_accuracy()


        print("\n" + "="*80)
        print("COMPREHENSIVE DNA STRUCTURE ANALYSIS REPORT")
        print("="*80)

        print("\nSECTION 1: DEMOGRAPHIC ANALYSIS SUMMARY")
        print("-" * 40)
        print("Key findings from the demographic analysis:")
        print(f"- Total samples: {len(self.data)}")
        print(f"- Gender distribution: {demographic_results['gender_dist'].to_dict()}")
        print(f"- Health status distribution: {demographic_results['health_dist'].to_dict()}")
        print(f"- Average age: {demographic_results['age_stats']['mean']:.1f}")
        print("\nVisualizations provided cover gender, race, age, health status distributions, GC content by health, structure/defect predictions, melting temp, and feature correlations.")

        print("\nSECTION 2: DEEP LEARNING MODEL PERFORMANCE SUMMARY")
        print("-" * 40)
        print("Evaluation metrics for the trained deep learning models:")

        print("\nStructure Prediction Models:")
        for model_name, metrics in overall_performance['structure_models'].items():
            print(f"  {model_name.replace('_', ' ').title()}: Accuracy={metrics['accuracy']:.4f}, F1={metrics['f1']:.4f}, AUC={metrics['roc_auc']:.4f}")

        print("\nStructural Defect Prediction Models:")
        for model_name, metrics in overall_performance['defect_models'].items():
             print(f"  {model_name.replace('_', ' ').title()}: Accuracy={metrics['accuracy']:.4f}, F1={metrics['f1']:.4f}, AUC={metrics['roc_auc']:.4f}")

        print("\nOverall System Performance (using Hybrid Models):")
        print(f"  Average Accuracy: {overall_performance['system_overall']['avg_accuracy']:.4f}")
        print(f"  Average F1 Score: {overall_performance['system_overall']['avg_f1']:.4f}")
        print(f"  Average ROC AUC:  {overall_performance['system_overall']['avg_roc_auc']:.4f}")

        print("\nVisualizations provided include ROC curves and comparison bar plots for Accuracy, F1, and AUC across models and tasks.")


        print("\nSECTION 3: INSIGHTS AND INTERPRETATIONS")
        print("-" * 40)
        print("Integrating demographic and model performance insights:")

        # Example insights (these would need to be more nuanced based on actual data analysis)
        print("- The hybrid model generally shows competitive performance across both structure and defect prediction tasks, suggesting value in combining numerical and sequence features.")
        print("- Demographic analysis highlights potential correlations between factors like age, health status, and certain DNA features (e.g., GC content), which are likely leveraged by the models.")
        print("- The confusion matrices indicate where models might be struggling (e.g., false positives or false negatives for specific classes).")
        print("- Further analysis could involve model interpretability techniques to understand which features (demographic or sequence-based) are most influential in predictions.")

        print("\nSECTION 4: INTERACTIVE MODE PREVIEW")
        print("-" * 40)
        print("The system includes an interactive mode (planned) to analyze a single DNA sequence based on trained models and user-provided demographics.")
        print("This mode will allow users to input:")
        print(" - A DNA Sequence")
        print(" - Demographic information (Gender, Race, Age, Health Status)")
        print("And receive predictions for 3D Structure and Structural Defects, along with feature calculations.")

        print("\n" + "="*80)
        print("REPORT CONCLUDED")
        print("="*80)

        return demographic_results, accuracy_results, overall_performance

    def run_interactive_analysis(self):
        """Run interactive mode for single DNA sequence analysis."""
        print("\n" + "="*80)
        print("INTERACTIVE DNA SEQUENCE ANALYSIS")
        print("="*80)

        if not self.models:
            print("Models are not trained. Please run training first.")
            return

        while True:
            # Get user input
            dna_sequence = input("Enter DNA Sequence (e.g., ATGCGTAC) or type 'quit' to exit: ").upper()

            if dna_sequence == 'QUIT':
                print("Exiting interactive analysis.")
                break

            # Basic validation for DNA sequence
            if not all(n in 'ATGC' for n in dna_sequence):
                print("Invalid DNA sequence. Please use only A, T, G, C.")
                continue

            # For the purpose of this interactive mode with current models,
            # we still need demographic input as the models predict structure/defect
            # based on sequence features AND demographic features.
            # To predict demographics from sequence would require training new models.
            try:
                gender = input("Enter Gender (Male/Female): ")
                race = input("Enter Race (e.g., Caucasian, African American, Asian, Hispanic, Native American, Mixed/Other): ")
                age = int(input("Enter Age: "))
                health_status = input("Enter Health Status (Healthy/Cardiovascular): ")
            except ValueError:
                print("Invalid input for Age. Please enter a number.")
                continue

            # Validate categorical inputs against trained data categories (optional but good practice)
            valid_genders = list(self.encoders['Gender'].classes_) if 'Gender' in self.encoders else ['Male', 'Female']
            valid_races = list(self.encoders['Race'].classes_) if 'Race' in self.encoders else ['Caucasian', 'African American', 'Asian', 'Hispanic', 'Native American', 'Mixed/Other']
            valid_health_statuses = list(self.encoders['Health_Status'].classes_) if 'Health_Status' in self.encoders else ['Healthy', 'Cardiovascular']

            # Provide feedback if input is not in training data categories
            if gender not in valid_genders:
                 print(f"Warning: Gender '{gender}' not seen in training data. Using closest match or default.")
                 gender_encoded = self.encoders['Gender'].transform([valid_genders[0]])[0] if 'Gender' in self.encoders else 0 # Use first class as default
            else:
                 gender_encoded = self.encoders['Gender'].transform([gender])[0]

            if race not in valid_races:
                 print(f"Warning: Race '{race}' not seen in training data. Using closest match or default.")
                 race_encoded = self.encoders['Race'].transform([valid_races[0]])[0] if 'Race' in self.encoders else 0 # Use first class as default
            else:
                 race_encoded = self.encoders['Race'].transform([race])[0]

            if health_status not in valid_health_statuses:
                 print(f"Warning: Health Status '{health_status}' not seen in training data. Using closest match or default.")
                 health_encoded = self.encoders['Health_Status'].transform([valid_health_statuses[0]])[0] if 'Health_Status' in self.encoders else 0 # Use first class as default
            else:
                 health_encoded = self.encoders['Health_Status'].transform([health_status])[0]


            # Prepare data for prediction
            # Calculate features for the input sequence
            def calculate_features_single(seq):
                # Ensure we handle empty sequence appropriately
                seq_len = len(seq) if seq else 1e-10 # Avoid division by zero
                features = {
                    'gc_content': (seq.count('G') + seq.count('C')) / seq_len,
                    'purine_content': (seq.count('A') + seq.count('G')) / seq_len,
                    'pyrimidine_content': (seq.count('C') + seq.count('T')) / seq_len,
                    'length': len(seq),
                    'a_count': seq.count('A'),
                    't_count': seq.count('T'),
                    'g_count': seq.count('G'),
                    'c_count': seq.count('C'),
                    'at_ratio': seq.count('A') / (seq.count('T') + 1e-10),
                    'gc_ratio': seq.count('G') / (seq.count('C') + 1e-10),
                    'cg_dinucleotides': seq.count('CG'),
                    'ta_dinucleotides': seq.count('TA'),
                    'at_dinucleotides': seq.count('AT'),
                    'gc_dinucleotides': seq.count('GC'),
                    'melting_temp': 2 * (seq.count('A') + seq.count('T')) + 4 * (seq.count('G') + seq.count('C')),
                    'stability_score': (seq.count('G') + seq.count('C')) * 4 + (seq.count('A') + seq.count('T')) * 2,
                    'twist_angle': 36.0 + np.random.normal(0, 2), # Synthetic structural features
                    'rise_per_bp': 3.4 + np.random.normal(0, 0.1),
                    'groove_width': 12.0 + np.random.normal(0, 1),
                    'backbone_distance': 20.0 + np.random.normal(0, 0.5)
                }
                return features

            input_features = calculate_features_single(dna_sequence)
            input_df = pd.DataFrame([input_features]) # Convert to dataframe

            # Add demographic features (using encoded values) - Align column names with training data
            input_df['Gender_encoded'] = gender_encoded
            input_df['Race_encoded'] = race_encoded
            input_df['Age'] = age
            input_df['Health_Status_encoded'] = health_encoded

            # Ensure the input dataframe has the same columns as the training data (in the same order)
            # This is crucial for consistent scaling and model input
            training_numerical_cols = list(self.X_numerical.columns) # Get columns from original training data before scaling
            input_numerical_data = input_df.reindex(columns=training_numerical_cols, fill_value=0) # Fill missing columns with 0


            # Scale numerical features using the same scaler fitted on training data
            input_numerical_scaled = self.scaler.transform(input_numerical_data)

            # Encode sequence
            input_sequence_encoded = self.encode_sequence(dna_sequence)
            input_sequence_encoded = np.array([input_sequence_encoded]) # Reshape for model prediction

            # Make predictions using the hybrid model (generally the most comprehensive)
            if 'hybrid_structure' in self.models and 'hybrid_defect' in self.models:
                structure_model = self.models['hybrid_structure']
                defect_model = self.models['hybrid_defect']

                # Predict structure
                structure_prob = structure_model.predict([input_numerical_scaled, input_sequence_encoded])[0][0] # Assuming sigmoid output
                structure_prediction_encoded = (structure_prob > 0.5).astype(int)
                structure_prediction = self.encoders['Structure_3D'].inverse_transform([structure_prediction_encoded])[0]

                # Predict defect
                defect_prob = defect_model.predict([input_numerical_scaled, input_sequence_encoded])[0][0] # Assuming sigmoid output
                defect_prediction_encoded = (defect_prob > 0.5).astype(int)
                defect_prediction = self.encoders['Structural_Defect'].inverse_transform([defect_prediction_encoded])[0]

                print("\n--- Analysis Results ---")
                print(f"Input DNA Sequence: {dna_sequence}")
                print(f"Provided Demographic Information:")
                print(f"  Gender: {gender}")
                print(f"  Race: {race}")
                print(f"  Age: {age} years")
                print(f"  Health Status: {health_status}")

                print("\nStructural Predictions:")
                print(f"  Predicted 3D Structure: {structure_prediction} (Confidence: {structure_prob:.4f})")
                print(f"  Predicted Structural Defect: {defect_prediction} (Confidence: {defect_prob:.4f})")

                print("\nCalculated Features:")
                for feature, value in input_features.items():
                     print(f"  {feature}: {value:.4f}")


            else:
                print("Hybrid models not found. Please train the models first.")

            print("\n" + "="*80)
            print("INTERACTIVE ANALYSIS CONCLUDED")
            print("="*80)

def main():
    """
    Main function to run the DNA Deep Learning Analysis pipeline.
    """
    analyzer = DNADeepLearningAnalyzer()

    # Step 1: Generate synthetic dataset
    print("Running Step 1: Generating synthetic dataset...")
    analyzer.generate_synthetic_dataset()

    # Step 2: Preprocess the data
    print("\nRunning Step 2: Preprocessing the data...")
    analyzer.preprocess_data()

    # Step 3: Train deep learning models
    print("\nRunning Step 3: Training deep learning models...")
    analyzer.train_deep_learning_models()

    # Step 4: Calculate and visualize comprehensive accuracy
    print("\nRunning Step 4: Calculating and visualizing comprehensive accuracy...")
    analyzer.calculate_comprehensive_accuracy()

    # Step 5: Generate comprehensive analysis report
    print("\nRunning Step 5: Generating comprehensive analysis report...")
    analyzer.comprehensive_analysis_report()

    # Step 6: Run interactive analysis (optional)
    print("\nRunning Step 6: Running interactive analysis...")
    analyzer.run_interactive_analysis()


if __name__ == "__main__":
    main()